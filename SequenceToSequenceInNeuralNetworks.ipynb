{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMr2Ggm7vk8JVACdnH6C+G9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuadV/ImplementingPapers/blob/main/SequenceToSequenceInNeuralNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38FlHHZi1jyY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter # to print to tensorboard\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlAT8ZKvOBqJ",
        "outputId": "6de48f4c-42ae-4d30-89e1-2fd8dfbb31fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "! python -m spacy download de"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU_Xf8c5XHMe"
      },
      "source": [
        "spacy_ger = spacy.load('de')\n",
        "spacy_eng = spacy.load('en')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvSww3vTNkJj"
      },
      "source": [
        "def tokenizer_ger(text):\n",
        "  \"\"\" Hello my name -> ['Hello', 'my', 'name']\"\"\"\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenizer_eng(text):\n",
        "  return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaFf1ipaOj8S"
      },
      "source": [
        "german = Field(tokenize=tokenizer_ger, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "english = Field(tokenize=tokenizer_eng, lower=True, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C7yQeQUPLlc"
      },
      "source": [
        "train_data, validation_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(german, english))\n",
        "\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI97muI0R7JV"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size= hidden_size\n",
        "\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x shape = (seq_length, N) # seq_length of words in N batches\n",
        "\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedding shape: (seq_len, N, embedding_size)\n",
        "    output, (hidden, cell) = self.rnn(embedding) \n",
        "    return hidden, cell\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-7tPMuyR_pi"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size,\n",
        "               num_layers, p): # input_size=output_size coz it will be prob of word in vocab 10000\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    # shape of x: (N) but we want (1, N) # 1 word at a time in N batches\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedding shape: (1, N, embedding_size)\n",
        "    outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "    # shape of outputs: (1, N, hidden_size)\n",
        "\n",
        "    predictions = self.fc(outputs)\n",
        "    # shape of predictions: (1, N, length_of_vocab)\n",
        "    predictions = predictions.squeeze(0)  # add ouput from decoder one step at a time. hence adding is simplified in this shape\n",
        "    return predictions, hidden, cell"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UadE0VBhSCR0"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target, teacher_force_ratio=0.5): # sometimes the prediction, sometimes the actual word when training\n",
        "    batch_size = source.shape[1]\n",
        "    # source: (trg_len, N)\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    hidden, cell = self.encoder(source)\n",
        "    # grab start token\n",
        "    x = target[0]\n",
        "\n",
        "    for t in range(target_len):\n",
        "      output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "\n",
        "      outputs[t] = output\n",
        "      # output: (N, eng_vocab_size) - argmax along 1st dimension to get the best guess of word perdicted\n",
        "      best_guess = output.argmax(1)\n",
        "\n",
        "      x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "    return outputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw0PVcH_1g5n"
      },
      "source": [
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "  print(f\"Loading checkpoint...\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "def save_checkpoint(state, filename='model_checkpoint.pth.tar'):\n",
        "  print(f\"Saving checkpoint: {filename}\")\n",
        "  torch.save(state, filename)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTIbhaTW1fhS"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, max_length, device):\n",
        "  tokenizer_ger = spacy.load('de')\n",
        "\n",
        "  if type(sentence) == str:\n",
        "    tokens = [tok.text.lower() for tok in tokenizer_ger(sentence)]\n",
        "  else:\n",
        "    tokens = [tok.lower() for tok in sentence]\n",
        "\n",
        "  tokens.insert(0, german.init_token)\n",
        "  tokens.append(german.eos_token)\n",
        "  token_indices = [german.vocab.stoi[tok] for tok in tokens]\n",
        "\n",
        "  sentence_tensor = torch.LongTensor(token_indices).unsqueeze(1).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    hidden, cell = model.encoder(sentence_tensor)\n",
        "\n",
        "  outputs = [german.vocab.stoi['<sos>']]\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "      best_guess = output.argmax(1).item()\n",
        "\n",
        "    outputs.append(best_guess)\n",
        "\n",
        "    if best_guess == english.vocab.stoi['<eos>']:\n",
        "      break\n",
        "\n",
        "  translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "  return translated_sentence[1:]\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vryTxg6SatN8",
        "outputId": "d8666919-6b92-4b00-fc9b-92e1117d869e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "\n",
        "# training hyperparameters\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "# model hyperparameters\n",
        "load_model = False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "input_size_encoder = len(german.vocab)\n",
        "input_size_decoder = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "enc_dropout = 0.5\n",
        "dec_dropout = 0.5\n",
        "num_layers = 2\n",
        "\n",
        "# Tensorboard\n",
        "writer = SummaryWriter(f'runs/loss_plot')\n",
        "step = 0\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data),\n",
        "    batch_size = batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key = lambda x: len(x.src), # sorts examples with similar length in batch. this saves on compute\n",
        "    device = device\n",
        ")\n",
        "\n",
        "encoder_net = Encoder(input_size=input_size_encoder, embedding_size=encoder_embedding_size, \n",
        "                      hidden_size=hidden_size, num_layers=num_layers, p=enc_dropout).to(device)\n",
        "decoder_net = Decoder(input_size=input_size_decoder, embedding_size=decoder_embedding_size, \n",
        "                      hidden_size=hidden_size, output_size=output_size, num_layers=num_layers, p=dec_dropout).to(device)\n",
        "model = Seq2Seq(encoder=encoder_net, decoder=decoder_net).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = english.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx) # ignore padding index\n",
        "\n",
        "if load_model:\n",
        "  load_checkpoint(torch.load('model_checkpoint.pth.tar'), model, optimizer)\n",
        "\n",
        "sentence = 'Ein Boot wurde von einem großen Team von Pferden gezogen'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch} / {num_epochs}')\n",
        "\n",
        "  checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "  save_checkpoint(checkpoint)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  translated_sentence = translate_sentence(model, sentence, german, english, max_length=50, device=device)\n",
        "  print(f\"\\nTranslated sentence: {' '.join(translated_sentence)}\")\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, batch in enumerate(tqdm(train_iterator)):\n",
        "    inp_data = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    output = model(inp_data, target)\n",
        "    # output shape: (trg_len, batch_size, output_dim)\n",
        "\n",
        "    output = output[1:].reshape(-1, output.shape[2]) # keep vocab lengt and combine all other dimensions\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Plot to tensorboard\n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "    step += 1\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: fairway fairway pocket headbands sweater operate beers fairway strap pocket populated pocket music music barbecue motorcyclist xylophone xylophone public outdoor outdoor walkman teal teal teal teal expression teal teal teal teal teal teal expression teal teal teal teal teal teal expression teal teal teal teal teal teal expression teal teal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:04<00:00,  7.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:27,  5.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a dog is a a a a a . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:05<00:00,  6.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a snowboarder is is to a a a the . . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:05<00:00,  6.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a skier is a a a a a . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:05<00:00,  6.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a hiker is a a a a a . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:21,  5.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a runner is through a race of a mountain . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a runner is being pulled by a a . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:29,  5.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a skier is being lifted by a large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:28,  5.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a boat is being pulled by a large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a boat is off a large large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a sheepdog is being pulled by a large large large bull . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a boat is being pulled by a large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:28,  5.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is being paddled by a large bull . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is off a large surrounded by large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is off a large large large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a sheepdog is away from a large large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is being pulled by a large large . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:18,  5.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is off a huge gate by large bull . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/454 [00:00<01:23,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is away from a large large gate . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19 / 20\n",
            "Saving checkpoint: model_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/454 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Translated sentence: a a bull is away from a large large gate . <eos>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 454/454 [01:06<00:00,  6.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEHbHOZhO9b"
      },
      "source": [
        "The translation of input sentence: \n",
        "\n",
        "'Ein Boot wurde von einem großen Team von Pferden gezogen'\n",
        "=>\n",
        "'A boat was pulled by a large team of horses'\n",
        "\n",
        "The model outputed '' after training of just 20 epochs.\n",
        "\n",
        "Need to train for more epochs to get better results.\n",
        "\n",
        "' a a boat is being pulled by a large large . <eos>' has been the best ouput so far"
      ]
    }
  ]
}